---
title: 生成AIのモデル選択について
tags: [AI]
---

- 主著 : Asuka Ohta
- 初版 : 2025-02-19
- 改稿 : 2025-03-10
  - 最近の動向について追加
- 改稿 : 2025-03-26
  - web 公開用の修正

生成AIをエンジニアリングに取り入れるという話題についてのレポートです。
ChatGPT o1 pro がリリースされた後、その使用感などについて聞かれることがあり、そうした質問への回答として書いたものです。

参考として ChatGPT との会話実例を添付しています。
同じ内容で問い合わせた3つのチャット実例が添付されていたものです。

- [o1 pro に deep research を使って問い合わせたもの](./appendix-chatgpt-o1pro-deep-research.md)
- [o3 に deep research を使って問い合わせたもの](./appendix-chatgpt-o3-deep-research.md)
- [o3 に web検索 のみ使って問い合わせたもの](./appendix-chatgpt-o3-search.md)

web 公開時点では修正できる内容も含まれていますが、原文ママとして公開します。

## introduction

生成AIの利用について所感を記載します。

筆者はITエンジニアとして、プログラミングやサーバ運用などの作業効率を向上するために生成AIを活用しています。
具体的には下記のようなタスクにおいて、生成AIに対する有用性を確認してきました。

- プログラミング
  - 要件からソースコードを生成する
  - 既存ソースコードに修正・改善提案をさせる
  - プログラミング中に生じた課題の解決（原因追究と対策の提案）
- ミドルウェアやフレームワークの選定情報の要約・比較検討
- ミドルウェア構成を含むインフラ設計支援（技術的課題の洗い出しと解決策の提案）

このレポートでは、上記のようなタスクを行う際にとくにどのモデルを利用するのがよいかを述べます。
対象となるのは下記モデルです。

- ChatGPT o1 pro（deep research モード）
- ChatGPT o3-mini-high（deep research モード、および通常の検索モード）

また、他社サービスとして Claude 3.7 にも触れます。
「現在使われている生成AIのモデルについての調査」タスクの結果も参照して評価した内容です。

結論としては、ChatGPT 系のモデルでは下記の順で良好な出力だと認識しています。

1. o1 pro (deep research)
2. o3-mini-high (deep research)
3. o3-mini-high (通常の検索モード)

さらに、後述する Claude 3.7 との組み合わせでコード修正などを円滑に行う事例も確認できました。

## 各モデルの特徴と結果

### o3-mini-high（通常の検索モード）

- 出力の特徴
  - 網羅的ではあるが情報が浅く、背景知識などの補完がない。
  - 多くの場合「箇条書きの羅列」あるいは「表を眺めているだけ」のような内容で、読者が本当に知りたいポイントを深掘りできない。
  - 不足情報を追加で質問しても、十分な補完をせず一問一答的に返す傾向が強い。

検索モードを用いず、単純にチャットとして用いても上記の特徴は変わりません。
また、上記の特徴は o1, o3 に共通する特徴です。

GPT-4o が言語処理に幅広く対応する汎用的なモデルなのに大して、o1, o3 は高度な推論（reasoning）能力に特化したモデルです。
このモデルは論証力や問題解決力が高いので本来プログラミング等のタスクに向いていますが、それでも評価としては限定的に有効なケースがある程度にとどまります。

たとえば、仕様にそぐうように書く、ありがちな問題に対応するよう修正するなど、公式のリファレンスを参照すればわかる程度のことに関しては対応できます。
それ以上に複雑な内容、いくつかの知識を組み合わせて問題を解決するようなタスクなどでは十分な力を発揮できません。

検索モードを用いることでリアルタイムな情報を利用できるようになりますが、後述の deep research モードと比べるとその恩恵は大きくありません。

### o3-mini-high（deep research モード）

- 推論能力と出力品質の向上
  - 論理的な説明や背景情報が増している。
  - 言及する内容間の論理的な構造が作られるようになり、通常モードで見られる「箇条書きの羅列」を脱している。
  - ソースコードを作らせた場合にも、単純に品質が向上する。
- 応答時間の増加
  - 実行時間が 5分～10分 程度かかる。

同じモデルでも deep research を有効にすることで、内容の品質が顕著に向上します。
deep research では部分的に o3 のフルサイズが使われること、推論のための時間が長くとられていることの2つが理由だと思われます。

deep research は調査・レポート生成の機能として捉えられがちですが、ソースコードの提案・修正のようなプログラミングタスクでも有効です。
公式の最新情報、GitHub 上に公開されているソースコード、コミュニティで提出されているイシューや質問などを調査した上で結果を返すので、よく検討された内容が得られます。

### o1 pro（deep research モード）

- より優れた文章生成
  - 背景を含めた読み物として成立するレベルの論述を行い、応答の品質は o3-mini-high より高いと感じられる。
- 安定性の懸念
  - リリース初期に deep research を開始できない（質問が繰り返される）不安定さを経験した。
  - そもそも通常検索を含むツールの使用は o1 pro ではサポートされていない。現状 deep research だけが o1 pro で動作しているが、正しい挙動なのか疑問。
- 応答時間
  - deep researchでは 5分～10分 程度

o3-mini-high と o1 pro の比較では、多くの場合で o1 pro の方が優れた返答を返します。
生成される文書の品質が高いことに加え、論理的な考察が o3-mini-high よりも高くなるので、プログラミング等のタスクにおいても o3-mini-high で解決できなかった課題を o1 pro が解決するシーンが存在します。

後継である o3 よりも o1 pro の方が良好な結果を返すことについては、 o3 が単純な o1 の能力向上版ではないことと o1 pro の特別性に起因していると思われます。
o3 は効率性に優れたモデルで、計算コストを抑えた o3-mini でも o1 並みか場合によっては o1 を超える結果を返す能力があるとされています。
一方、o1 pro は通常の o1 以上に推論・思考の深さが大きくとられたモデルなので、deep research モードで o3 のフルサイズが部分的に利用されてなお o1 pro の方が高い推論能力を発揮しても不思議ではありません。

o1 pro は長い推論時間を取るモデルのため、通常チャットでも 数分～10分 程度の応答待ち時間が生じます。
deep research によりさらに長い時間を待つ可能性を考えましたが、いまのところ o3-mini-high と同程度に収まっています。
とはいえ o1 pro は安定性に懸念があり、また非常に計算コストの高いモデルなので利用制限等の制限を受ける可能性も考えられるため、強く勧めることが難しいと感じています。
出力品質は良好なので、それらの点が解消すれば優れた選択肢と言えるでしょう。

### deep research の影響

deep research について何度か触れました。
deep research を有効にすることで、通常のチャットと比べて何が変わるのかを以下にまとめます。

- リアルタイム情報
  - 検索機能を用いない場合、生成AIは学習時点の知識に基づいて回答する。
  - o1 pro の場合では、1,2年前に大きな更新があったフレームワークについては、古い情報でしか回答できないことが多い。
- 推論能力の向上 (とくに o3-mini)
  - 通常モード時に比べて文脈を深く理解し、適切なソリューションを提案する。
  - deep research では o3-mini ではなくフルサイズの o3 が利用される
- 文章の打ち切り防止
  - 通常チャットでは出力文字数制限があるのか長い論述ができない。
  - 必要な内容では途中の内容が浅くなったり、唐突にまとめに入ろうとする傾向がある。
  - deep research の出力は通常チャットのものより長い。途中の論述も深くなり、全体像を把握しやすい。
- 利用制限
  - リリース時に X 上で pro プランユーザー限定の利用、月に100回までの利用制限だとアナウンスされている。
  - 公式サイト上の pricing としては明記がない。またこれまでに制限を受けた経験がないため、真実性が不明。

## 他サービスとの比較

ここでは ChatGPT についてのみ触れました。他社サービスと比較して ChatGPT が一歩先んじていたためです。
以下で他社サービスとの比較について触れます。

- Claude 等の他社サービス
  - o1 pro が出るまではおおよそ同程度の性能という印象。
  - o1 pro のリリース後、o1 pro が頭一つ抜けた存在として長く存在していた。
  - deep research に匹敵するものもなかったため、さらに差が開いた。
- Google gemini・perplexity pro などのAI検索サービス
  - AI検索の競合として見ると、おおよそ同程度。つまり o3-mini-high 通常検索で感じる不満を共通で抱えている。
  - 参照元のリンクが無効（デッドリンク）のケースもあり、検索AIとしての完成度に疑問がある。
- Google gemini の deep research モード
  - 最新版 (ver 2.0) ではなく古いモデル (ver 1.5) が利用されている。推論能力の不足が顕著。
  - レポート冒頭と結論で内容が矛盾するなどの論理破綻がしばしば見られた。

## 最新の動向

本レポート初期バージョン執筆時点では上記のような内容でした。
その後、状況にいくつかの変化がありました。

### ChatGPT GPT-4.5 のリリース

最新のモデル GPT-4.5 がリリースされました。

結論から述べると、このモデルは本レポートの目的からすると興味を払う必要のないものです。
推論能力を重視とした o1, o3 に対して GPT-4.5 の能力の評価ポイントは EQ (感情知性) が優れているといったものです。

本レポートでAIに行わせるタスクは、論理的な思考を必要とするタスクがほとんどです。
各種ベンチマークでも高い結果を出しているとは言えず、最新モデルではありますが、o1, o3 からの乗り換え先になることはないでしょう。

### Claude 3.7 のリリースと Cursor からの利用

Claude 3.7 がリリースされました。雑に評価するなら ChatGPT o1 もしくは o1 pro 相当の推論能力を持っていると扱えるものです。
実際ベンチマークでも claude-3.7-sonnet-thinking モデルが o1 に対して近い数値でやや優越という扱いになることが多いです。

claude 3.7 はすでに利用可能な ChatGPT o3 や o1 pro から比べて完全に上位にあるような乗り換え先でありませんが、別の用途において大きな価値を示しています。

Cursor はプロジェクト全体のコードベースをインデックス化しながら、エージェントモードで複数ファイルの修正提案を半自動的に行える環境です。
類似のプロダクトはいくつかありますが、それらから claude-3.7-sonnet-thinking モデルを利用できます。

このアプローチにより、以下のような利点が得られました。

- コードベース全体の一貫性を保った修正
  - codebase インデックスを参照して修正するため、呼び出し関係が破綻しにくい。
- 大きな文書やコードを取り扱う
  - チャット画面にすべて貼り付ける手間や制限を気にせず、継続的に処理できる。
- 修正やコーディングの半自動化
  - おおまかな指示から実行計画を組み立て、実施することができる。
  - 実行計画にも claude-3.7-sonnet-thinking モデルが使われるため、明記していない留意事項もある程度推定して実行する。
  - lint エラーや test 失敗を検知しての修正ループを自動で回すような処理がされる。

課題や注意点もあります。

- codebase を参照させない場合、整合性が失われて機能しないコードを生成しやすい。
- 実コードによるものではなく、アーキテクチャ全体に対する考察、方針提案では o1 deep research の方が優れている。
- 複雑なタスクでは複数回の修正指示が必要。コンテキストを忘れて同じ問題が再発することがある。
- バグ修正やビルド通過に注力しすぎ、当初の目的とずれたコードが生成される場合がある。

Claude 3.7 は明確に ChatGPT に優越した存在ではないですが、ChatGPT とは異なるユースケースを実現できるという点で Claude は注目すべき対象となりました。
ChatGPT deep research は、インターネット上から必要な情報を収集して包括的にレポートをまとめる能力があり、この点が相変わらず強力です。
Claude 3.7 自体はその機能はありませんが、巨大なコンテキストを扱えるため、大量のソースコードや文書をまとめて入力する形での分析には向いています。
情報収集を ChatGPT deep research に任せ、Claude 3.7 で長文・大規模なコード修正や詳細分析を行う組み合わせをとる事例もあり、cursor からの利用でも限定的ではありますが、有効に機能することも確認できました。

## まとめ

- 通常のチャットでは o3-mini-high より o1 pro が高品質。
- deep research を付与した o3-mini-high は大幅に精度が上がり、ほとんどの高度なタスクをカバーできる。
- o1 pro deep research は推論能力がさらに高いが、応答時間や安定性に課題があり、利用制限が生じる可能性もある。
- ChatGPT 系に限らず見た場合、Claude 3.7 + Cursor の組み合わせは大規模コードリファクタリングで有用性が高い。
- deep research か o1 pro のいずれかを採用しない場合、複雑なタスクで推論不足を感じやすい。
- リアルタイム情報が必要な場合、ChatGPT の通常検索だけでは力不足なので deep research が有力。
- Cursor における Claude 3.7 のエージェント修正は効率が高いが、方針立案を別のモデル (o1 pro deep research など) に任せたほうがよい場合もある。

今後も新バージョンや機能改善の動向を継続して確認しながら最適なモデル選択を検討しますが、現時点では ChatGPT deep research での高度な調査と、Claude 3.7 + Cursor の大規模コード解析の双方に利点があるため、タスクの内容やチームの方針に応じて使い分けるとよいと考えています。
